{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estudo parametrico de um algoritmo imunológico em um problema de classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Separar em 10 pastas de tamanho igual (15)\n",
    "\n",
    "9 para treino e 1 para teste\n",
    "\n",
    "10 execuções\n",
    "\n",
    "Cada execução testo numa nova pasta (decremental)\n",
    "\n",
    "Média e desvio padrão dos 10 testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy\n",
    "# !pip install pandas\n",
    "# !pip install sklearn\n",
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "import clonalg\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Anticorpos treinados com exemplos de iris virginica [label 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/iris.csv', header=None)\n",
    "\n",
    "df[4] = pd.Categorical(df[4]).codes\n",
    "labels = df[[4]].copy()\n",
    "\n",
    "df = df.drop(columns=[4])\n",
    "\n",
    "#Standard Scaler\n",
    "scaler = preprocessing.StandardScaler()\n",
    "train = pd.DataFrame(scaler.fit_transform(df.values), columns=df.columns, index=df.index)\n",
    "\n",
    "#Train dataset\n",
    "train = train.join(labels)\n",
    "# O valor de train[4] define qual label será utilizada para o treino da população\n",
    "train = train.loc[train[4] == 0]\n",
    "train = train.drop(columns=[4])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Métodos de normalização além do StandartScaler deverão ser testados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "feature_num = len(train.axes[1])\n",
    "feature_max = train.max()\n",
    "feature_max  = feature_max.max()\n",
    "feature_min = train.min()\n",
    "feature_min  = feature_min.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Definição de hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "population_size = 400\n",
    "selection_size = 50\n",
    "memory_set_percentage = 50\n",
    "\n",
    "clone_rate = 40 ## Clone rate - 1 (Step 5 +-)\n",
    "mutation_rate = 0.3\n",
    "stop_codition = 100\n",
    "\n",
    "\n",
    "d = 15 ## Individuos aleatorios - 2 (Step 2.5 +-)\n",
    "sigma1 = 0.9\n",
    "sigma2 = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Conversão de dataframe para numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train = train.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![](resources/V7zasui.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stop = 0\n",
    "population = clonalg.create_random_cells(population_size, feature_num, feature_min, feature_max)\n",
    "\n",
    "while stop != stop_codition:\n",
    "    # 1.\n",
    "    for antigen in train:\n",
    "        # 1.1\n",
    "        population_affinity = [(cell, clonalg.affinity(cell, antigen)) for cell in population]\n",
    "        # 1.2\n",
    "        population_affinity = sorted(population_affinity, key=lambda x: abs(x[1]))\n",
    "        best_affinity = population_affinity[:selection_size]\n",
    "        # 1.3\n",
    "        clone_population = []\n",
    "        for cell in best_affinity:\n",
    "            cell_clones = clonalg.clone(cell, clone_rate)\n",
    "            clone_population += cell_clones\n",
    "        # 1.4 - 1.5\n",
    "        mutaded_clone_population = []\n",
    "        for cell in clone_population:\n",
    "            mutated_clone = clonalg.hypermutate_variability(cell, mutation_rate, antigen)\n",
    "            mutaded_clone_population.append(mutated_clone)\n",
    "        # 1.6\n",
    "        mutaded_clone_population.sort(key=lambda x: x[1])\n",
    "        pop_size = round(len(clone_population)/100)*memory_set_percentage\n",
    "\n",
    "        mutaded_clone_population = mutaded_clone_population[0:pop_size]\n",
    "\n",
    "        # 1.7\n",
    "        filtered_clone_population = list(filter(lambda x: x[1] < sigma2, mutaded_clone_population))\n",
    "\n",
    "        # 1.8\n",
    "        remaining_clone_population = clonalg.remove_similar_clones(filtered_clone_population, sigma1)\n",
    "\n",
    "        # 1.9\n",
    "        # Remova o atributo de afinidade das células em remaining_clone_population\n",
    "        remaining_clone_population_no_affinity = [(cell[0],) for cell in remaining_clone_population]\n",
    "        # Adicione remaining_clone_population_no_affinity à população\n",
    "        population = population + remaining_clone_population_no_affinity\n",
    "\n",
    "    # 2.0\n",
    "    population = clonalg.suppress_similar_cells(population, sigma1)\n",
    "        \n",
    "    # 3\n",
    "    new_cells = clonalg.create_random_cells(int(population_size * (d / 100)), feature_num, feature_min, feature_max)\n",
    "    population += new_cells\n",
    "    print(\"População: \", len(population), \"     Iteração: \", stop)\n",
    "    stop += 1\n",
    "\n",
    "## Solução temporária para nested arrays nos indivíduos da população.\n",
    "\n",
    "for i, cell in enumerate(population):\n",
    "    # Verifica se a célula tem mais de uma dimensão\n",
    "    if len(cell[0].shape) > 1:\n",
    "        # Aplica numpy.ravel() para simplificar as dimensões\n",
    "        flattened_cell = np.ravel(cell[0])\n",
    "        population[i] = (flattened_cell,)\n",
    "    else:\n",
    "        population[i] = cell\n",
    "        \n",
    "    if isinstance(cell, tuple):\n",
    "        array_cell = np.array(cell)\n",
    "        flattened_cell = np.ravel(array_cell)\n",
    "        population[i] = (flattened_cell)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, cell in enumerate(population):\n",
    "    # Verifica se a célula tem mais de uma dimensão\n",
    "    if len(cell[0].shape) > 1:\n",
    "        # Aplica numpy.ravel() para simplificar as dimensões\n",
    "        flattened_cell = np.ravel(cell[0])\n",
    "        population[i] = (flattened_cell,)\n",
    "    else:\n",
    "        population[i] = cell\n",
    "        \n",
    "    if isinstance(cell, tuple):\n",
    "        array_cell = np.array(cell)\n",
    "        flattened_cell = np.ravel(array_cell)\n",
    "        population[i] = (flattened_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "antibodies = pd.DataFrame(population)\n",
    "antibodies = pd.DataFrame(scaler.inverse_transform(antibodies), columns=antibodies.columns)\n",
    "antibodies_array = antibodies.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "antibodies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Extract the feature vectors from the population\n",
    "feature_vectors = np.array([cell for cell in antibodies_array])\n",
    "\n",
    "\n",
    "# Apply PCA to reduce the dimensionality to 3\n",
    "pca = PCA(n_components=3)\n",
    "reduced_population = pca.fit_transform(feature_vectors)\n",
    "\n",
    "# Now, you can plot the reduced population using a 3D scatter plot\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "x = reduced_population[:, 0]\n",
    "y = reduced_population[:, 1]\n",
    "z = reduced_population[:, 2]\n",
    "\n",
    "ax.scatter(x, y, z)\n",
    "\n",
    "ax.set_xlabel('Principal Component 1')\n",
    "ax.set_ylabel('Principal Component 2')\n",
    "ax.set_zlabel('Principal Component 3')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "feature_vectors = np.array([cell for cell in antibodies_array])\n",
    "\n",
    "x = feature_vectors[:, 0]\n",
    "y = feature_vectors[:, 1]\n",
    "z = feature_vectors[:, 2]\n",
    "c = feature_vectors[:, 3]\n",
    "\n",
    "img = ax.scatter(x, y, z, c=c, cmap=plt.hot())\n",
    "fig.colorbar(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/iris.csv', header=None)\n",
    "\n",
    "df[4] = pd.Categorical(df[4]).codes\n",
    "labels = df[[4]].copy()\n",
    "\n",
    "df = df.drop(columns=[4])\n",
    "\n",
    "#Standard Scaler\n",
    "scaler = preprocessing.StandardScaler()\n",
    "train = pd.DataFrame(df)\n",
    "\n",
    "#Train dataset\n",
    "train = train.join(labels)\n",
    "train = train.loc[train[4] == 2]\n",
    "train = train.drop(columns=[4])\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "train_array = train.values\n",
    "\n",
    "feature_vectors = np.array([cell for cell in train_array])\n",
    "\n",
    "x = feature_vectors[:, 0]\n",
    "y = feature_vectors[:, 1]\n",
    "z = feature_vectors[:, 2]\n",
    "c = feature_vectors[:, 3]\n",
    "\n",
    "img = ax.scatter(x, y, z, c=c, cmap=plt.hot())\n",
    "fig.colorbar(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/iris.csv', header=None)\n",
    "\n",
    "df[4] = pd.Categorical(df[4]).codes\n",
    "labels = df[[4]].copy()\n",
    "\n",
    "df = df.drop(columns=[4])\n",
    "\n",
    "#Standard Scaler\n",
    "scaler = preprocessing.StandardScaler()\n",
    "train = pd.DataFrame(df)\n",
    "\n",
    "#Train dataset\n",
    "train = train.join(labels)\n",
    "train = train.loc[train[4] == 1]\n",
    "train = train.drop(columns=[4])\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "train_array = train.values\n",
    "\n",
    "feature_vectors = np.array([cell for cell in train_array])\n",
    "\n",
    "x = feature_vectors[:, 0]\n",
    "y = feature_vectors[:, 1]\n",
    "z = feature_vectors[:, 2]\n",
    "c = feature_vectors[:, 3]\n",
    "\n",
    "img = ax.scatter(x, y, z, c=c, cmap=plt.hot())\n",
    "fig.colorbar(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/iris.csv', header=None)\n",
    "\n",
    "df[4] = pd.Categorical(df[4]).codes\n",
    "labels = df[[4]].copy()\n",
    "\n",
    "df = df.drop(columns=[4])\n",
    "\n",
    "#Standard Scaler\n",
    "scaler = preprocessing.StandardScaler()\n",
    "train = pd.DataFrame(df)\n",
    "\n",
    "#Train dataset\n",
    "train = train.join(labels)\n",
    "train = train.loc[train[4] == 0]\n",
    "train = train.drop(columns=[4])\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "train_array = train.values\n",
    "\n",
    "feature_vectors = np.array([cell for cell in train_array])\n",
    "\n",
    "x = feature_vectors[:, 0]\n",
    "y = feature_vectors[:, 1]\n",
    "z = feature_vectors[:, 2]\n",
    "c = feature_vectors[:, 3]\n",
    "\n",
    "img = ax.scatter(x, y, z, c=c, cmap=plt.hot())\n",
    "fig.colorbar(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from train_loop import train_ais_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/iris.csv', header=None)\n",
    "\n",
    "df[4] = pd.Categorical(df[4]).codes\n",
    "labels = df[[4]].copy()\n",
    "\n",
    "df = df.drop(columns=[4])\n",
    "\n",
    "# Standard Scaler\n",
    "scaler = preprocessing.StandardScaler()\n",
    "train = pd.DataFrame(scaler.fit_transform(df.values), columns=df.columns, index=df.index)\n",
    "train = train.join(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_num = train.shape[1] - 1  # Menos a coluna de labels\n",
    "feature_min = train.iloc[:, :-1].min().min()  # Menos a coluna de labels\n",
    "feature_max = train.iloc[:, :-1].max().max()  # Menos a coluna de labels\n",
    "\n",
    "# Treine o classificador AIS para cada classe (0, 1, 2) e armazene os resultados em uma lista\n",
    "trained_populations = []\n",
    "for class_label in range(3):\n",
    "    train_class = train.loc[train[4] == class_label]\n",
    "    train_class = train_class.drop(columns=[4])\n",
    "    train_class = train_class.to_numpy()\n",
    "    population = train_ais_classifier(train_class, feature_num, feature_min, feature_max)\n",
    "    trained_populations.append(population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import clonalg\n",
    "from train_loop import multiclass_performance_measure\n",
    "\n",
    "df = pd.read_csv('dataset/iris.csv', header=None)\n",
    "\n",
    "df[4] = pd.Categorical(df[4]).codes\n",
    "labels = df[[4]].copy()\n",
    "\n",
    "df = df.drop(columns=[4])\n",
    "\n",
    "# Standard Scaler\n",
    "scaler = preprocessing.StandardScaler()\n",
    "train = pd.DataFrame(scaler.fit_transform(df.values), columns=df.columns, index=df.index)\n",
    "train = train.join(labels)\n",
    "# Dividir o conjunto de dados em treino e teste\n",
    "train_data, test_data = train_test_split(train, test_size=0.3, random_state=42)\n",
    "\n",
    "test_data_array = test_data.values\n",
    "performance = multiclass_performance_measure(trained_populations, test_data_array)\n",
    "print(f\"Desempenho do classificador AIS: {performance * 100:.2f}%\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multithread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "População:  87      Iteração:  0\n",
      "População:  88      Iteração:  0\n",
      "População:  103      Iteração:  0\n",
      "Desempenho do classificador AIS: 28.89%\n"
     ]
    }
   ],
   "source": [
    "from train_loop import train_clonalg_parallel\n",
    "from train_loop import multiclass_performance_measure\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "df = pd.read_csv('dataset/iris.csv', header=None)\n",
    "\n",
    "df[4] = pd.Categorical(df[4]).codes\n",
    "labels = df[[4]].copy()\n",
    "\n",
    "df = df.drop(columns=[4])\n",
    "\n",
    "# Standard Scaler\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "train = pd.DataFrame(scaler.fit_transform(df.values), columns=df.columns, index=df.index)\n",
    "train = train.join(labels)\n",
    "# Dividir o conjunto de dados em treino e teste\n",
    "train_data, test_data = train_test_split(train, test_size=0.3, random_state=42)\n",
    "\n",
    "params = {\n",
    "    'population_size': 300,\n",
    "    'selection_size': 50,\n",
    "    'memory_set_percentage': 50,\n",
    "    'clone_rate': 15,\n",
    "    'mutation_rate': 0.3,\n",
    "    'stop_condition': 100,\n",
    "    'd': 10,\n",
    "    'sigma1': 0.9,\n",
    "    'sigma2': 0.1,\n",
    "    'feature_num': train_data.shape[1] - 1,\n",
    "    'feature_min': train_data.min().min(),\n",
    "    'feature_max': train_data.max().max(),\n",
    "}\n",
    "\n",
    "trained_populations = train_clonalg_parallel(train_data, params, [0, 1, 2])\n",
    "\n",
    "# Avaliar o desempenho do classificador AIS\n",
    "test_data_array = test_data.values\n",
    "performance = multiclass_performance_measure(trained_populations, test_data_array)\n",
    "print(f\"Desempenho do classificador AIS: {performance * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "População:  101      Iteração:  0\n",
      "População:  101      Iteração:  0\n",
      "População:  96      Iteração:  0\n",
      "População:  121      Iteração:  1\n",
      "População:  126      Iteração:  1\n",
      "População:  127      Iteração:  1\n",
      "População:  133      Iteração:  2\n",
      "População:  134      Iteração:  2\n",
      "População:  147      Iteração:  2\n",
      "População:  148      Iteração:  3\n",
      "População:  138      Iteração:  3\n",
      "População:  153      Iteração:  3\n",
      "População:  147      Iteração:  4\n",
      "População:  158      Iteração:  4\n",
      "População:  148      Iteração:  4\n",
      "População:  158      Iteração:  5\n",
      "População:  151      Iteração:  5\n",
      "População:  159      Iteração:  5\n",
      "População:  157      Iteração:  6\n",
      "População:  152      Iteração:  6\n",
      "População:  150      Iteração:  6\n",
      "População:  142      Iteração:  7\n",
      "População:  152      Iteração:  7\n",
      "População:  158      Iteração:  8\n",
      "População:  155      Iteração:  7\n",
      "População:  158      Iteração:  8\n",
      "População:  148      Iteração:  9\n",
      "População:  146      Iteração:  8\n",
      "População:  152      Iteração:  9\n",
      "População:  137      Iteração:  9\n",
      "\n",
      "//////////////////////////////////////////////\n",
      "\n",
      "Relatório de classificação para a pasta 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      1.00      0.63         6\n",
      "           1       0.00      0.00      0.00         6\n",
      "           2       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.40        15\n",
      "   macro avg       0.15      0.33      0.21        15\n",
      "weighted avg       0.18      0.40      0.25        15\n",
      "\n",
      "\n",
      "//////////////////////////////////////////////\n",
      "\n",
      "População:  107      Iteração:  0\n",
      "População:  112      Iteração:  0\n",
      "População:  120      Iteração:  0\n",
      "População:  129      Iteração:  1\n",
      "População:  136      Iteração:  1\n",
      "População:  131      Iteração:  1\n",
      "População:  128      Iteração:  2\n",
      "População:  150      Iteração:  2\n",
      "População:  135      Iteração:  2\n",
      "População:  138      Iteração:  3\n",
      "População:  150      Iteração:  3\n",
      "População:  150      Iteração:  3\n",
      "População:  142      Iteração:  4\n",
      "População:  157      Iteração:  4\n",
      "População:  150      Iteração:  4\n",
      "População:  156      Iteração:  5\n",
      "População:  151      Iteração:  5\n",
      "População:  152      Iteração:  5\n",
      "População:  151      Iteração:  6\n",
      "População:  154      Iteração:  6\n",
      "População:  153      Iteração:  6\n",
      "População:  147      Iteração:  7\n",
      "População:  155      Iteração:  7\n",
      "População:  140      Iteração:  8\n",
      "População:  149      Iteração:  7\n",
      "População:  151      Iteração:  8\n",
      "População:  137      Iteração:  9\n",
      "População:  152      Iteração:  9\n",
      "População:  143      Iteração:  8\n",
      "População:  133      Iteração:  9\n",
      "\n",
      "//////////////////////////////////////////////\n",
      "\n",
      "Relatório de classificação para a pasta 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.20      1.00      0.33         3\n",
      "           2       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.20        15\n",
      "   macro avg       0.07      0.33      0.11        15\n",
      "weighted avg       0.04      0.20      0.07        15\n",
      "\n",
      "\n",
      "//////////////////////////////////////////////\n",
      "\n",
      "População:  103      Iteração:  0\n",
      "População:  110      Iteração:  0\n",
      "População:  113      Iteração:  0\n",
      "População:  128      Iteração:  1\n",
      "População:  136      Iteração:  1\n",
      "População:  122      Iteração:  1\n",
      "População:  135      Iteração:  2\n",
      "População:  143      Iteração:  2\n",
      "População:  139      Iteração:  2\n",
      "População:  143      Iteração:  3\n",
      "População:  139      Iteração:  3\n",
      "População:  146      Iteração:  3\n",
      "População:  148      Iteração:  4\n",
      "População:  148      Iteração:  4\n",
      "População:  142      Iteração:  4\n",
      "População:  140      Iteração:  5\n",
      "População:  146      Iteração:  5\n",
      "População:  143      Iteração:  5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from train_loop import multiclass_performance_measure_v2\n",
    "from train_loop import train_clonalg_parallel\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "df = pd.read_csv('dataset/iris.csv', header=None)\n",
    "\n",
    "df[4] = pd.Categorical(df[4]).codes\n",
    "labels = df[[4]].copy()\n",
    "\n",
    "df = df.drop(columns=[4])\n",
    "\n",
    "# Standard Scaler\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "train = pd.DataFrame(scaler.fit_transform(df.values), columns=df.columns, index=df.index)\n",
    "train = train.join(labels)\n",
    "\n",
    "# Crie um objeto KFold\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Armazenar as métricas de desempenho de cada iteração\n",
    "performance_scores = []\n",
    "# Armazenar todas as verdadeiras e previstas etiquetas através das divisões\n",
    "all_true_labels = []\n",
    "all_predicted_labels = []\n",
    "\n",
    "train_data, test_data = train_test_split(train, test_size=0.3, random_state=42)\n",
    "\n",
    "params = {\n",
    "    'population_size': 400,\n",
    "    'selection_size': 50,\n",
    "    'memory_set_percentage': 50,\n",
    "    'clone_rate': 15,\n",
    "    'mutation_rate': 0.3,\n",
    "    'stop_condition': 10,\n",
    "    'd': 15,\n",
    "    'sigma1': 0.9,\n",
    "    'sigma2': 0.1,\n",
    "    'feature_num': train_data.shape[1] - 1,\n",
    "    'feature_min': train_data.min().min(),\n",
    "    'feature_max': train_data.max().max(),\n",
    "}\n",
    "\n",
    "# Loop através das divisões de treinamento e teste\n",
    "for i, (train_index, test_index) in enumerate(kfold.split(train), start=1):\n",
    "    # Dividir o conjunto de dados em treinamento e teste com base nos índices\n",
    "    train_data = train.iloc[train_index]\n",
    "    test_data = train.iloc[test_index]\n",
    "\n",
    "    # Treinar o classificador AIS\n",
    "    trained_populations = train_clonalg_parallel(train_data, params, [0, 1, 2])\n",
    "\n",
    "    # Avaliar o desempenho do classificador AIS\n",
    "    test_data_array = test_data.values\n",
    "    accuracy, true_labels, predicted_labels = multiclass_performance_measure_v2(trained_populations, test_data_array)\n",
    "    performance_scores.append(accuracy)\n",
    "\n",
    "    # Estender all_true_labels e all_predicted_labels com os rótulos verdadeiros e previstos da iteração atual\n",
    "    all_true_labels.extend(true_labels)\n",
    "    all_predicted_labels.extend(predicted_labels)\n",
    "\n",
    "    # Imprimir o relatório de classificação para a iteração atual\n",
    "    print(\"\\n//////////////////////////////////////////////\\n\")\n",
    "    print(f\"Relatório de classificação para a pasta {i}:\")\n",
    "    print(classification_report(true_labels, predicted_labels))\n",
    "    print(\"\\n//////////////////////////////////////////////\\n\")\n",
    "\n",
    "# Calcular a precisão média\n",
    "print(\"\\n//////////////////////////////////////////////\\n\")\n",
    "mean_accuracy = np.mean(performance_scores)\n",
    "print(f\"Desempenho médio do classificador AIS: {mean_accuracy * 100:.2f}%\")\n",
    "print(\"\\n//////////////////////////////////////////////\\n\")\n",
    "\n",
    "# Calcular e exibir a matriz de confusão combinada\n",
    "print(\"\\n//////////////////////////////////////////////\\n\")\n",
    "conf_matrix = confusion_matrix(all_true_labels, all_predicted_labels)\n",
    "print(\"Matriz de confusão:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\n//////////////////////////////////////////////\\n\")\n",
    "\n",
    "# Calcular e exibir o relatório de classificação combinado\n",
    "print(\"\\n//////////////////////////////////////////////\\n\")\n",
    "class_report = classification_report(all_true_labels, all_predicted_labels)\n",
    "print(\"Relatório de classificação:\")\n",
    "print(class_report)\n",
    "print(\"\\n//////////////////////////////////////////////\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "c3503f95e0e8f4afdf6702396a7a2a29cae9f67572acfe092405dcaa2579b817"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
